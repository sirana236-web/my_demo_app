#!/usr/bin/env python3
"""
ğŸ”® Customer Churn Prediction â€” Live Demo (v2 â€” Fixed)
======================================================
Ø§Ø¬Ø±Ø§:
    streamlit run app.py

ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§:
    pip install streamlit pandas numpy scikit-learn joblib plotly
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  IMPORTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import sys
import warnings
import hashlib
import json
from pathlib import Path

warnings.filterwarnings("ignore")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  VERSION TRACKING â€” Ø­Ù„ Ù…Ø´Ú©Ù„ Ù†Ø§Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ù†Ø³Ø®Ù‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import sklearn
SKLEARN_VERSION = sklearn.__version__

def _get_version_file() -> Path:
    return Path("models") / "_sklearn_version.txt"

def _is_version_compatible() -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù†Ø³Ø®Ù‡ ÙØ¹Ù„ÛŒ scikit-learn Ø³Ø§Ø²Ú¯Ø§Ø± Ù‡Ø³ØªÙ†Ø¯."""
    vf = _get_version_file()
    if not vf.exists():
        return False
    saved_version = vf.read_text().strip()
    # ÙÙ‚Ø· major.minor Ø¨Ø§ÛŒØ¯ ÛŒÚ©ÛŒ Ø¨Ø§Ø´Ø¯ (Ù…Ø«Ù„Ø§Ù‹ 1.3 == 1.3)
    current_major_minor = ".".join(SKLEARN_VERSION.split(".")[:2])
    saved_major_minor   = ".".join(saved_version.split(".")[:2])
    return current_major_minor == saved_major_minor

def _save_version():
    _get_version_file().write_text(SKLEARN_VERSION)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATA_PATH    = "test_data.csv"
MODELS_DIR   = "models"
HIGH_THRESH  = 0.70
MED_THRESH   = 0.40

NUMERIC_FEATS = [
    "age", "tenure_months", "monthly_revenue", "total_spend",
    "num_support_tickets", "monthly_usage_hours", "num_products",
    "satisfaction_score", "last_login_days",
]
CATEGORICAL_FEATS = ["contract_type", "payment_method"]
ALL_FEATS = NUMERIC_FEATS + CATEGORICAL_FEATS

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Churn Prediction âˆ™ Live Demo",
    page_icon="ğŸ”®",
    layout="wide",
    initial_sidebar_state="collapsed",
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CUSTOM CSS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.markdown("""
<style>
/* â”€â”€ Ù…Ø®ÙÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù…Ù†ÙˆØŒ ÙÙˆØªØ±ØŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ â”€â”€ */
#MainMenu, footer, header,
[data-testid="stElementToolbar"],
.stDeployButton,
[data-testid="stBaseButton-headerNoPadding"],
button[title="Download"],
[data-testid="StyledFullScreenButton"] {
    display: none !important;
    visibility: hidden !important;
}

html, body, [class*="css"] {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}

.metric-card {
    background: linear-gradient(145deg, #1a1a2e, #16213e);
    border: 1px solid #2a2a50;
    border-radius: 18px;
    padding: 26px 18px;
    text-align: center;
    box-shadow: 0 10px 30px rgba(0,0,0,0.4);
    transition: transform 0.3s ease, box-shadow 0.3s ease;
}
.metric-card:hover {
    transform: translateY(-7px);
    box-shadow: 0 14px 40px rgba(0,0,0,0.55);
}
.mc-icon  { font-size: 2.2rem; margin-bottom: 6px; }
.mc-label {
    font-size: 0.78rem; color: #7a7fa0;
    text-transform: uppercase; letter-spacing: 2px;
}
.mc-value { font-size: 2.3rem; font-weight: 800; margin-top: 4px; }

.c-blue   { color: #6C63FF; }
.c-red    { color: #FF4B4B; }
.c-yellow { color: #FFB020; }
.c-green  { color: #00CC66; }

.risk-bar {
    display: flex; height: 10px;
    border-radius: 6px; overflow: hidden; margin: 8px 0 4px 0;
}
.risk-bar > div { transition: width 0.6s ease; }

.sep {
    height: 2px; border: none; margin: 28px 0;
    background: linear-gradient(90deg, transparent, #6C63FF44, transparent);
}

.sub {
    text-align: center; color: #7a7fa0;
    margin-top: -10px; margin-bottom: 26px;
    font-size: 1.05rem;
}
</style>
""", unsafe_allow_html=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SETUP â€” Ø³Ø§Ø®Øª Ø¯Ø§Ø¯Ù‡ + Ù…Ø¯Ù„ (ÙÙ‚Ø· Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ù†Ø³Ø®Ù‡ Ø¹ÙˆØ¶ Ø´Ø¯Ù‡)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _make_test_csv(n: int = 250) -> pd.DataFrame:
    """Ø³Ø§Ø®Øª test_data.csv Ù†Ù…ÙˆÙ†Ù‡."""
    rng = np.random.default_rng(42)
    df = pd.DataFrame({
        "user_id":              [f"USR-{i:04d}" for i in range(1, n + 1)],
        "age":                  rng.integers(18, 68, n),
        "tenure_months":        rng.integers(1, 72, n),
        "monthly_revenue":      np.round(rng.uniform(15, 550, n), 2),
        "total_spend":          np.round(rng.uniform(200, 30_000, n), 2),
        "num_support_tickets":  rng.integers(0, 18, n),
        "monthly_usage_hours":  np.round(rng.uniform(1, 220, n), 1),
        "num_products":         rng.integers(1, 6, n),
        "satisfaction_score":   rng.integers(1, 6, n),
        "last_login_days":      rng.integers(0, 90, n),
        "contract_type":        rng.choice(
            ["Monthly", "Quarterly", "Annual"], n, p=[0.50, 0.30, 0.20]),
        "payment_method":       rng.choice(
            ["Credit Card", "Bank Transfer", "Digital Wallet"], n,
            p=[0.40, 0.35, 0.25]),
    })
    df.to_csv(DATA_PATH, index=False)
    return df


def _purge_old_models():
    """Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ù¾ÙˆØ´Ù‡ models/ Ù‚Ø¨Ù„ Ø§Ø² Ø³Ø§Ø®Øª Ù…Ø¬Ø¯Ø¯."""
    import shutil
    if os.path.exists(MODELS_DIR):
        shutil.rmtree(MODELS_DIR)
    os.makedirs(MODELS_DIR, exist_ok=True)


def _make_models():
    """Ø³Ø§Ø®Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Pipeline Ùˆ Ø°Ø®ÛŒØ±Ù‡ â€” Ø¨Ø§ Ù†Ø³Ø®Ù‡ ÙØ¹Ù„ÛŒ scikit-learn."""
    from sklearn.ensemble import (
        RandomForestClassifier,
        GradientBoostingClassifier,
    )
    from sklearn.linear_model import LogisticRegression
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline

    _purge_old_models()

    # â”€â”€ Preprocessor â”€â”€
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), NUMERIC_FEATS),
            ("cat", OneHotEncoder(
                drop="first",
                sparse_output=False,
                handle_unknown="ignore",
            ), CATEGORICAL_FEATS),
        ],
        remainder="drop",
    )

    # â”€â”€ Ø¯Ø§Ø¯Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù…ØµÙ†ÙˆØ¹ÛŒ â”€â”€
    rng = np.random.default_rng(99)
    N   = 2_000
    X_train = pd.DataFrame({
        "age":                  rng.integers(18, 68, N),
        "tenure_months":        rng.integers(1, 72, N),
        "monthly_revenue":      np.round(rng.uniform(15, 550, N), 2),
        "total_spend":          np.round(rng.uniform(200, 30_000, N), 2),
        "num_support_tickets":  rng.integers(0, 18, N),
        "monthly_usage_hours":  np.round(rng.uniform(1, 220, N), 1),
        "num_products":         rng.integers(1, 6, N),
        "satisfaction_score":   rng.integers(1, 6, N),
        "last_login_days":      rng.integers(0, 90, N),
        "contract_type":        rng.choice(
            ["Monthly", "Quarterly", "Annual"], N),
        "payment_method":       rng.choice(
            ["Credit Card", "Bank Transfer", "Digital Wallet"], N),
    })

    # â”€â”€ Ø¨Ø±Ú†Ø³Ø¨ Ù…ØµÙ†ÙˆØ¹ÛŒ â”€â”€
    score = (
        0.22 * (X_train["num_support_tickets"] / 18)
        + 0.20 * (1 - X_train["tenure_months"] / 72)
        + 0.15 * (1 - X_train["monthly_usage_hours"] / 220)
        + 0.13 * (1 - X_train["satisfaction_score"] / 5)
        + 0.12 * (X_train["last_login_days"] / 90)
        + 0.08 * (X_train["contract_type"] == "Monthly").astype(float)
        + 0.10 * rng.uniform(0, 1, N)
    )
    y_train = (score > 0.48).astype(int)

    # â”€â”€ Ø³Ø§Ø®Øª + Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø± Ù…Ø¯Ù„ â”€â”€
    classifiers = {
        "random_forest": RandomForestClassifier(
            n_estimators=150, max_depth=8, random_state=42,
        ),
        "gradient_boosting": GradientBoostingClassifier(
            n_estimators=120, max_depth=5, random_state=42,
        ),
        "logistic_regression": LogisticRegression(
            max_iter=1_000, random_state=42,
        ),
    }

    for name, clf in classifiers.items():
        pipe = Pipeline([
            ("preprocessor", preprocessor),
            ("classifier",   clf),
        ])
        pipe.fit(X_train[ALL_FEATS], y_train)

        path = os.path.join(MODELS_DIR, f"{name}.pkl")
        joblib.dump(pipe, path, protocol=4)   # protocol=4 â†’ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨ÛŒØ´ØªØ±

    # â”€â”€ Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª â”€â”€
    cfg = {
        "numeric":     NUMERIC_FEATS,
        "categorical": CATEGORICAL_FEATS,
        "all":         ALL_FEATS,
    }
    joblib.dump(cfg, os.path.join(MODELS_DIR, "feature_config.pkl"), protocol=4)

    # â”€â”€ Ø«Ø¨Øª Ù†Ø³Ø®Ù‡ â”€â”€
    _save_version()

    return True


def _ensure_models_ready():
    """
    Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ù†Ø³Ø®Ù‡.
    Ø§Ú¯Ø± Ù†Ø³Ø®Ù‡ Ø¹ÙˆØ¶ Ø´Ø¯Ù‡ â†’ Ù¾Ø§Ú© + Ø³Ø§Ø®Øª Ù…Ø¬Ø¯Ø¯.
    """
    models_exist = (
        os.path.exists(MODELS_DIR)
        and len(list(Path(MODELS_DIR).glob("*.pkl"))) >= 3
    )

    if not models_exist or not _is_version_compatible():
        return _make_models()
    return True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CORE FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_data(show_spinner=False)
def load_data() -> pd.DataFrame:
    if not os.path.exists(DATA_PATH):
        _make_test_csv()
    return pd.read_csv(DATA_PATH)


@st.cache_resource(show_spinner=False)
def load_models() -> tuple:
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ â€” Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ÛŒ Ù†Ø³Ø®Ù‡."""

    _ensure_models_ready()

    models = {}
    for p in sorted(Path(MODELS_DIR).glob("*.pkl")):
        if p.stem in ("feature_config", "_sklearn_version"):
            continue
        try:
            models[p.stem] = joblib.load(p)
        except (AttributeError, ModuleNotFoundError, ImportError) as e:
            # âš ï¸ Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ø®Ø·Ø§ÛŒ Ù†Ø³Ø®Ù‡ Ø¨ÙˆØ¯ â†’ Ù¾Ø§Ú© + Ø³Ø§Ø®Øª Ù…Ø¬Ø¯Ø¯
            st.warning(f"âš ï¸ Ù…Ø¯Ù„ `{p.stem}` Ù†Ø§Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨ÙˆØ¯ØŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯...")
            _make_models()
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ø¯Ø¯
            models = {}
            for pp in sorted(Path(MODELS_DIR).glob("*.pkl")):
                if pp.stem in ("feature_config", "_sklearn_version"):
                    continue
                models[pp.stem] = joblib.load(pp)
            break

    cfg_path = Path(MODELS_DIR) / "feature_config.pkl"
    cfg = joblib.load(cfg_path) if cfg_path.exists() else {
        "numeric": NUMERIC_FEATS,
        "categorical": CATEGORICAL_FEATS,
        "all": ALL_FEATS,
    }
    return models, cfg


def risk_label(prob: float) -> str:
    if prob >= HIGH_THRESH:
        return "High"
    if prob >= MED_THRESH:
        return "Medium"
    return "Low"


def run_prediction(model, df: pd.DataFrame, cfg: dict) -> np.ndarray:
    """Ø§Ø¬Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ â€” Pipeline Ø®ÙˆØ¯Ø´ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    feat_cols = cfg.get("all", ALL_FEATS)
    X = df[feat_cols].copy()
    probs = model.predict_proba(X)[:, 1]
    return probs


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  UI HELPERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _card(icon, label, value, css_color):
    st.markdown(f"""
    <div class="metric-card">
        <div class="mc-icon">{icon}</div>
        <div class="mc-label">{label}</div>
        <div class="mc-value {css_color}">{value}</div>
    </div>""", unsafe_allow_html=True)


def render_summary(total, n_high, n_med, n_low, rev_at_risk):
    c1, c2, c3, c4, c5 = st.columns(5)
    with c1: _card("ğŸ‘¥", "Total Customers",  f"{total:,}",            "c-blue")
    with c2: _card("ğŸš¨", "High Risk",        f"{n_high:,}",           "c-red")
    with c3: _card("âš ï¸",  "Medium Risk",      f"{n_med:,}",            "c-yellow")
    with c4: _card("âœ…", "Low Risk",         f"{n_low:,}",            "c-green")
    with c5: _card("ğŸ’°", "Revenue at Risk",  f"${rev_at_risk:,.0f}",  "c-red")


def render_risk_bar(h_pct, m_pct, l_pct):
    st.markdown(f"""
    <div style="display:flex;justify-content:space-between;
                font-size:.82rem;margin-top:20px">
        <span class="c-red">â—  High  {h_pct:.1f}%</span>
        <span class="c-yellow">â—  Medium  {m_pct:.1f}%</span>
        <span class="c-green">â—  Low  {l_pct:.1f}%</span>
    </div>
    <div class="risk-bar">
        <div style="width:{h_pct}%;background:#FF4B4B"></div>
        <div style="width:{m_pct}%;background:#FFB020"></div>
        <div style="width:{l_pct}%;background:#00CC66"></div>
    </div>""", unsafe_allow_html=True)


def styled_results(df: pd.DataFrame):
    """Ø§Ø³ØªØ§ÛŒÙ„â€ŒØ¯Ù‡ÛŒ Ø¬Ø¯ÙˆÙ„ Ù†ØªØ§ÛŒØ¬ â€” Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ Ù‡Ø± Ù†Ø³Ø®Ù‡ pandas."""

    def _risk_style(v):
        colors = {
            "High":   "background:#FF4B4B30;color:#FF4B4B;font-weight:700",
            "Medium": "background:#FFB02030;color:#FFB020;font-weight:700",
            "Low":    "background:#00CC6630;color:#00CC66;font-weight:700",
        }
        return colors.get(v, "")

    def _prob_style(v):
        if v >= HIGH_THRESH:
            return "color:#FF4B4B;font-weight:700"
        if v >= MED_THRESH:
            return "color:#FFB020;font-weight:700"
        return "color:#00CC66;font-weight:700"

    styler = df.style

    # â”€â”€ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ pandas â‰¥2.1 Ùˆ <2.1 â”€â”€
    if hasattr(styler, "map"):
        styler = styler.map(_risk_style, subset=["risk_level"])
        styler = styler.map(_prob_style, subset=["churn_probability"])
    else:
        styler = styler.applymap(_risk_style, subset=["risk_level"])
        styler = styler.applymap(_prob_style, subset=["churn_probability"])

    styler = styler.format({
        "churn_probability": "{:.1%}",
        "monthly_revenue":   "${:,.2f}",
    })
    return styler


def render_charts(results: pd.DataFrame):
    try:
        import plotly.express as px
        import plotly.graph_objects as go
    except ImportError:
        st.info("ğŸ“¦  `pip install plotly` Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø±")
        return

    col_a, col_b = st.columns(2)

    with col_a:
        counts = results["risk_level"].value_counts().reindex(
            ["High", "Medium", "Low"], fill_value=0)
        fig1 = go.Figure(go.Pie(
            labels=counts.index, values=counts.values,
            hole=0.55,
            marker_colors=["#FF4B4B", "#FFB020", "#00CC66"],
            textinfo="label+percent",
            textfont_size=13,
        ))
        fig1.update_layout(
            title_text="Risk Distribution", title_x=0.5,
            showlegend=False,
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)",
            font_color="#ccc", height=340,
            margin=dict(t=50, b=20, l=20, r=20),
        )
        st.plotly_chart(fig1, use_container_width=True)

    with col_b:
        fig2 = px.histogram(
            results, x="churn_probability", nbins=30,
            color_discrete_sequence=["#6C63FF"],
        )
        fig2.add_vline(x=HIGH_THRESH, line_dash="dash",
                       line_color="#FF4B4B", annotation_text="High")
        fig2.add_vline(x=MED_THRESH, line_dash="dash",
                       line_color="#FFB020", annotation_text="Medium")
        fig2.update_layout(
            title_text="Probability Distribution", title_x=0.5,
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)",
            font_color="#ccc", height=340,
            margin=dict(t=50, b=20, l=20, r=20),
            xaxis_title="Churn Probability",
            yaxis_title="Count",
            showlegend=False,
        )
        st.plotly_chart(fig2, use_container_width=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    # â”€â”€â”€â”€ HEADER â”€â”€â”€â”€
    st.markdown(
        "<h1 style='text-align:center;"
        "background:linear-gradient(135deg,#6C63FF,#E040FB);"
        "-webkit-background-clip:text;"
        "-webkit-text-fill-color:transparent;"
        "font-size:2.6rem;font-weight:900;"
        "padding:12px 0'>"
        "ğŸ”®  Customer Churn Prediction System</h1>",
        unsafe_allow_html=True,
    )
    st.markdown(
        "<p class='sub'>Realâ€‘time churn risk analysis Â· "
        "Powered by Machine Learning</p>",
        unsafe_allow_html=True,
    )

    # â”€â”€ Ù†Ù…Ø§ÛŒØ´ Ù†Ø³Ø®Ù‡ scikit-learn â”€â”€
    st.markdown(
        f"<p style='text-align:center;color:#555;font-size:.75rem'>"
        f"scikit-learn v{SKLEARN_VERSION} &nbsp;Â·&nbsp; "
        f"Python {sys.version.split()[0]}</p>",
        unsafe_allow_html=True,
    )

    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)

    # â”€â”€â”€â”€ LOAD â”€â”€â”€â”€
    with st.spinner("â³  Loading data & models â€¦"):
        data = load_data()
        models, cfg = load_models()

    if not models:
        st.error("âŒ  Ù‡ÛŒÚ† Ù…Ø¯Ù„ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯! Ù¾ÙˆØ´Ù‡ `models/` Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
        st.stop()

    # â”€â”€â”€â”€ MODEL SELECTOR â”€â”€â”€â”€
    st.markdown("#### âš™ï¸  Model Selection")
    pretty = {k: k.replace("_", " ").title() for k in models}

    col_s, col_i = st.columns([2, 3])
    with col_s:
        sel = st.selectbox("Choose a model:", list(models.keys()),
                           format_func=lambda x: pretty[x])
    with col_i:
        m = models[sel]
        if hasattr(m, "named_steps"):
            steps = " â†’ ".join(m.named_steps.keys())
            st.info(f"ğŸ”— **Pipeline:** `{steps}`")
        else:
            st.info(f"ğŸ“¦ Model: `{type(m).__name__}`")

    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)

    # â”€â”€â”€â”€ PREDICT â”€â”€â”€â”€
    try:
        probs = run_prediction(models[sel], data, cfg)
    except Exception as exc:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ: {exc}")
        # ÛŒÚ© Ø¨Ø§Ø± Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ
        st.warning("ğŸ”„ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ ...")
        _make_models()
        st.cache_resource.clear()
        st.rerun()

    results = pd.DataFrame({
        "user_id":           data["user_id"],
        "churn_probability": probs,
        "risk_level":        [risk_label(p) for p in probs],
        "monthly_revenue":   data["monthly_revenue"],
    }).sort_values("churn_probability", ascending=False).reset_index(drop=True)

    # â”€â”€â”€â”€ METRICS â”€â”€â”€â”€
    total   = len(results)
    high_df = results[results.risk_level == "High"]
    med_df  = results[results.risk_level == "Medium"]
    low_df  = results[results.risk_level == "Low"]
    n_high, n_med, n_low = len(high_df), len(med_df), len(low_df)
    rev_risk  = high_df["monthly_revenue"].sum()
    total_rev = results["monthly_revenue"].sum()
    h_pct = n_high / total * 100
    m_pct = n_med  / total * 100
    l_pct = n_low  / total * 100

    # â”€â”€â”€â”€ DASHBOARD â”€â”€â”€â”€
    st.markdown("### ğŸ“Š  Dashboard Summary")
    render_summary(total, n_high, n_med, n_low, rev_risk)
    render_risk_bar(h_pct, m_pct, l_pct)
    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)

    # â”€â”€â”€â”€ CHARTS â”€â”€â”€â”€
    st.markdown("### ğŸ“ˆ  Visual Overview")
    render_charts(results)
    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)

    # â”€â”€â”€â”€ FILTERS â”€â”€â”€â”€
    st.markdown("### ğŸ”  Filter & Explore")
    f1, f2, f3 = st.columns([2, 2, 1])
    with f1:
        risk_filter = st.multiselect(
            "Risk Level:", ["High", "Medium", "Low"],
            default=["High", "Medium", "Low"],
        )
    with f2:
        top_n = st.slider("Show Top N:", 10, total, min(50, total), 10)
    with f3:
        sort_col = st.selectbox(
            "Sort by:",
            ["churn_probability", "monthly_revenue"],
            format_func=lambda x: x.replace("_", " ").title(),
        )

    view = (
        results[results.risk_level.isin(risk_filter)]
        .sort_values(sort_col, ascending=False)
        .head(top_n)
    )

    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)

    # â”€â”€â”€â”€ TABLE â”€â”€â”€â”€
    st.markdown(
        f"### ğŸ“‹  Prediction Results â€” "
        f"Showing **{len(view):,}** of {total:,}")

    st.dataframe(
        styled_results(view),
        use_container_width=True,
        height=520,
        hide_index=True,
    )

    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)

    # â”€â”€â”€â”€ TOP 5 HIGH RISK â”€â”€â”€â”€
    st.markdown("### ğŸš¨  Top 5 Highâ€‘Risk Customers")
    top5 = high_df.head(5)
    if top5.empty:
        st.success("âœ… Ù‡ÛŒÚ† Ù…Ø´ØªØ±ÛŒ High Risk ÛŒØ§ÙØª Ù†Ø´Ø¯!")
    else:
        cols = st.columns(len(top5))
        for i, (_, row) in enumerate(top5.iterrows()):
            with cols[i]:
                st.markdown(f"""
                <div class="metric-card" style="border-color:#FF4B4B55">
                    <div style="font-size:1.1rem;font-weight:700;
                                color:#FF4B4B;margin-bottom:8px">
                        {row.user_id}
                    </div>
                    <div style="font-size:.8rem;color:#8892b0">
                        Churn: <b style="color:#FF4B4B">
                        {row.churn_probability:.1%}</b>
                    </div>
                    <div style="font-size:.8rem;color:#8892b0;margin-top:4px">
                        Revenue: <b style="color:#FFB020">
                        ${row.monthly_revenue:,.2f}</b>
                    </div>
                </div>""", unsafe_allow_html=True)

    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)

    # â”€â”€â”€â”€ DETAILED STATS â”€â”€â”€â”€
    with st.expander("ğŸ“Š  Detailed Statistics", expanded=False):
        s1, s2, s3 = st.columns(3)
        with s1:
            st.markdown("##### Churn Probability")
            st.metric("Mean",   f"{results.churn_probability.mean():.1%}")
            st.metric("Median", f"{results.churn_probability.median():.1%}")
            st.metric("Std",    f"{results.churn_probability.std():.1%}")
        with s2:
            st.markdown("##### Revenue")
            st.metric("Total Revenue",   f"${total_rev:,.0f}")
            st.metric("Revenue at Risk", f"${rev_risk:,.0f}")
            ratio = (rev_risk / total_rev * 100) if total_rev else 0
            st.metric("Risk Ratio",      f"{ratio:.1f}%")
        with s3:
            st.markdown("##### Distribution")
            st.metric("High",   f"{n_high:,}  ({h_pct:.1f}%)")
            st.metric("Medium", f"{n_med:,}  ({m_pct:.1f}%)")
            st.metric("Low",    f"{n_low:,}  ({l_pct:.1f}%)")

    # â”€â”€â”€â”€ FOOTER â”€â”€â”€â”€
    st.markdown("<div class='sep'></div>", unsafe_allow_html=True)
    st.markdown(
        "<p style='text-align:center;color:#555;font-size:.82rem;padding:10px 0'>"
        "ğŸ”® Churn Prediction v2.0 Â· Fixed Edition</p>",
        unsafe_allow_html=True,
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    main()